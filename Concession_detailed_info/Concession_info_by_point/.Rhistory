load("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/200819_new pine data/200819_tmspine_reg.RData")
View(southern_reg)
names(southern_reg)
south_S2_old <- glm(S_2 ~ ppt.f.10y + ppt.sp.10y + ppt.su.10y + ppt.w.10y + tmean.f.10y + tmean.sp.10y + tmean.su.10y + tmean.w.10y +
ppt.f.10y_sq + ppt.sp.10y_sq + ppt.su.10y_sq + ppt.w.10y_sq +
tmean.f.10y_sq + tmean.sp.10y_sq + tmean.su.10y_sq + tmean.w.10y_sq +
SLOPE + south_face + Xeric + Hydric + avg_co2_10y +
pop_density + PPI_sw + PPI_hw + private, data = southern_reg_final, family = binomial)
summary(south_S2_old)
southern_reg_final <- merge(x = tms_pine_FIA_long, y = southern_reg,
by.x = c("year", "fips", "tmscd"), by.y = c("INVYR", "STATECD", "TMSCD"))
southern_reg <- merge(fia_tms_region, southern_reg, by = c("STATECD", "UNITCD"))
southern_reg_final <- merge(x = tms_pine_FIA_long, y = southern_reg,
by.x = c("year", "fips", "tmscd"), by.y = c("INVYR", "STATECD", "TMSCD"))
south_S2_old <- glm(S_2 ~ ppt.f.10y + ppt.sp.10y + ppt.su.10y + ppt.w.10y + tmean.f.10y + tmean.sp.10y + tmean.su.10y + tmean.w.10y +
ppt.f.10y_sq + ppt.sp.10y_sq + ppt.su.10y_sq + ppt.w.10y_sq +
tmean.f.10y_sq + tmean.sp.10y_sq + tmean.su.10y_sq + tmean.w.10y_sq +
SLOPE + south_face + Xeric + Hydric + avg_co2_10y +
pop_density + PPI_sw + PPI_hw + private, data = southern_reg_final, family = binomial)
summary(south_S2_old)
south_S2_tms <- glm(S_2 ~ ppt.f.10y + ppt.sp.10y + ppt.su.10y + ppt.w.10y + tmean.f.10y + tmean.sp.10y + tmean.su.10y + tmean.w.10y +
ppt.f.10y_sq + ppt.sp.10y_sq + ppt.su.10y_sq + ppt.w.10y_sq +
tmean.f.10y_sq + tmean.sp.10y_sq + tmean.su.10y_sq + tmean.w.10y_sq +
SLOPE + south_face + Xeric + Hydric + avg_co2_10y +
pop_density + tms_price + PPI_hw + private, data = southern_reg_final, family = binomial)
summary(south_S2_tms)
names(southern_reg_final)
southern_reg_final$statefactor <- as.factor(southern_reg_final$State)
south_S2_tms <- glm(S_2 ~ ppt.f.10y + ppt.sp.10y + ppt.su.10y + ppt.w.10y + tmean.f.10y + tmean.sp.10y + tmean.su.10y + tmean.w.10y +
ppt.f.10y_sq + ppt.sp.10y_sq + ppt.su.10y_sq + ppt.w.10y_sq +
tmean.f.10y_sq + tmean.sp.10y_sq + tmean.su.10y_sq + tmean.w.10y_sq +
SLOPE + south_face + Xeric + Hydric + avg_co2_10y +
pop_density + tms_price + PPI_hw + private +statefactor, data = southern_reg_final, family = binomial)
summary(south_S2_tms)
south_S2_old <- glm(S_2 ~ ppt.f.10y + ppt.sp.10y + ppt.su.10y + ppt.w.10y + tmean.f.10y + tmean.sp.10y + tmean.su.10y + tmean.w.10y +
ppt.f.10y_sq + ppt.sp.10y_sq + ppt.su.10y_sq + ppt.w.10y_sq +
tmean.f.10y_sq + tmean.sp.10y_sq + tmean.su.10y_sq + tmean.w.10y_sq +
SLOPE + south_face + Xeric + Hydric + avg_co2_10y +
pop_density + PPI_sw + PPI_hw + private + statefactor, data = southern_reg_final, family = binomial)
summary(south_S2_old)
save.image("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/200819_new pine data/200819_tmspine_reg.RData")
load("C:/Users/liu34/OneDrive/OSU/Working Papers/4 Forest Substitution/Data/210127_variable values_inventory/210127_variable_values.RData")
View(plant_reg)
View(plant_reg)
View(plant_reg)
test_reg <- lm(avg_area ~ p_pnw)
test_reg <- lm(avg_area ~ p_pnw, data = plant_reg)
summary(test_reg)
help(aggregate)
load("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/210720_new_species/.RData")
model_fn(Sale_Price ~ Neighborhood + Year_Sold,
data = ames)
vfold_cv(ames, v = 10)
bootstraps(ames,times = 10)
library(rsample)   # for resampling procedures
bootstraps(ames,times = 10)
vfold_cv(ames, v = 10)
set.seed(123)
split <- initial_split(ames, prop = 0.7,
strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)
head(ames)
# Specify resampling strategy
cv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
library(caret)     # for resampling and model training
library(h2o)       # for resampling and model training
cv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
# Create grid of hyperparameter values
hyper_grid <- expand.grid(k = seq(2, 25, by = 1))
# Tune a knn model using grid search
knn_fit <- train(
Sale_Price ~ .,
data = ames_train,
method = "knn",
trControl = cv,
tuneGrid = hyper_grid,
metric = "RMSE"
)
knn_fit
ggplot(knn_fit)
library(visdat)    # for additional visualizations
install.packages("visdat")
install.packages("recipes")
save.image("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/210720_new_species/210811_machineLearningTest.RData")
install.packages("recipes")
install.packages("recipes")
install.packages("recipes")
install.packages("recipes")
install.packages("recipes")
library(visdat)    # for additional visualizations
library(recipes)  # for feature engineering tasks
sum(is.na(AmesHousing::ames_raw))
AmesHousing::ames_raw %>%
is.na() %>%
reshape2::melt() %>%
ggplot(aes(Var2, Var1, fill=value)) +
geom_raster() +
coord_flip() +
scale_y_continuous(NULL, expand = c(0, 0)) +
scale_fill_grey(name = "",
labels = c("Present",
"Missing")) +
xlab("Observation") +
theme(axis.text.y  = element_text(size = 4))
library(ggplot2)   # for awesome graphics
AmesHousing::ames_raw %>%
is.na() %>%
reshape2::melt() %>%
ggplot(aes(Var2, Var1, fill=value)) +
geom_raster() +
coord_flip() +
scale_y_continuous(NULL, expand = c(0, 0)) +
scale_fill_grey(name = "",
labels = c("Present",
"Missing")) +
xlab("Observation") +
theme(axis.text.y  = element_text(size = 4))
vis_miss(AmesHousing::ames_raw, cluster = TRUE)
count(ames_train, Neighborhood) %>% arrange(n)
count(ames_train, Screen_Porch) %>% arrange(n)
count(ames_train, Screen_Porch)
count(ames_train, Neighborhood)
# Lump levels for two features
lumping <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_other(Neighborhood, threshold = 0.01,
other = "other") %>%
step_other(Screen_Porch, threshold = 0.1,
other = ">0")
View(lumping)
apply_2_training <- prep(lumping, training = ames_train) %>%
bake(ames_train)
count(apply_2_training, Neighborhood) %>% arrange(n)
count(apply_2_training, Neighborhood)
count(ames_train, Neighborhood)
count(ames_train, Neighborhood) %>% arrange(n)
count(apply_2_training, Neighborhood) %>% arrange(n)
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal())  %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_pca(all_numeric(), -all_outcomes())
blueprint
prepare <- prep(blueprint, training = ames_train)
prepare
baked_train <- bake(prepare, new_data = ames_train)
baked_test <- bake(prepare, new_data = ames_test)
baked_train
View(ames_train)
blueprint <- recipe(Sale_Price ~ ., data = ames_train) %>%
step_nzv(all_nominal()) %>%
step_integer(matches("Qual|Cond|QC|Qu")) %>%
step_center(all_numeric(), -all_outcomes()) %>%
step_scale(all_numeric(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)
blueprint
# Specify resampling plan
cv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 5
)
# Construct grid of hyperparameter values
hyper_grid <- expand.grid(k = seq(2, 25, by = 1))
# Tune a knn model using grid search
knn_fit2 <- train(
blueprint,
data = ames_train,
method = "knn",
trControl = cv,
tuneGrid = hyper_grid,
metric = "RMSE"
)
library(dplyr)     # for data manipulation
library(ggplot2)   # for awesome graphics
library(visdat)    # for additional visualizations
# Modeling process packages
library(rsample)   # for resampling procedures
library(modeldata)
library(caret)     # for resampling and model training
library(h2o)       # for resampling and model training
library(recipes)  # for feature engineering tasks
knn_fit2 <- train(
blueprint,
data = ames_train,
method = "knn",
trControl = cv,
tuneGrid = hyper_grid,
metric = "RMSE"
)
knn_fit2
ggplot(knn_fit2)
save.image("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/210720_new_species/210811_machineLearningTest.RData")
load("C:/Users/liu34/OneDrive/OSU/Working Papers/2 Forest Movement/Data/210720_new_species/210811_machineLearningTest.RData")
# Helper packages
library(dplyr)       # for data wrangling
library(ggplot2)     # for awesome plotting
# Modeling packages
library(rpart)       # direct engine for decision tree application
library(caret)       # meta engine for decision tree application
# Model interpretability packages
library(rpart.plot)  # for plotting decision trees
library(vip)         # for feature importance
library(pdp)         # for feature effects
ames_dt1 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova"
)
ames_dt1
rpart.plot(ames_dt1)
ames_dt2 <- rpart(
formula = Sale_Price ~ .,
data    = ames_train,
method  = "anova",
control = list(cp = 0, xval = 10)
)
plotcp(ames_dt2)
abline(v = 11, lty = "dashed")
ames_dt3 <- train(
Sale_Price ~ .,
data = ames_train,
method = "rpart",
trControl = trainControl(method = "cv", number = 10),
tuneLength = 20
)
ggplot(ames_dt3)
vip(ames_dt3, num_features = 40, bar = FALSE)
load("C:/Users/liu34/OneDrive/OSU/Working Papers/4 Forest Substitution/Data/210604_modified analysis/R_plant_data/.RData")
library(tidyverse)
load("C:/Users/liu34/OneDrive/OSU/Working Papers/4 Forest Substitution/Data/210604_modified analysis/R_plant_data/210909_additionalVars.RData")
setwd("~/GitHub/Guyana-concesssion/Concession_detailed_info")
library(readr)
Concession_info_MTOverlap <- read_csv("Concession_info_MTOverlap.csv")
View(Concession_info_MTOverlap)
library(readr)
Concession_info_TimberOnly <- read_csv("Concession_info_TimberOnly.csv")
View(Concession_info_TimberOnly)
colnames(Concession_info_TimberOnly)
libraray(tidyverse)
library(tidyverse)
info_TimberOnly <- Concession_info_TimberOnly %>%
select(UID, OWNER, TYPE, ACRES)
info_MTOverlap <- Concession_info_MTOverlap %>%
select(UID, OWNER, TYPE, ACRES)
library(haven)
Panel_C_T <- read_dta("~/GitHub/Guyana-concesssion/Stata-logit-regression/Panel_C_T.dta")
View(Panel_C_T)
library(haven)
Panel_C_MT <- read_dta("~/GitHub/Guyana-concesssion/Stata-logit-regression/Panel_C_MT.dta")
View(Panel_C_MT)
## Change dataframe names and combine with concession info
Panel_C_MT_logit <- Panel_C_MT
Panel_C_T_logit <- Panel_C_T
rm(Panel_C_MT, Panel_C_T)
Panel_C_MT_logit <- merge(Panel_C_MT_logit, info_MTOverlap, by = c("UID"))
View(Panel_C_MT_logit)
Panel_C_T <- Panel_C_T_logit
library(haven)
Panel_C_MT <- read_dta("~/GitHub/Guyana-concesssion/Stata-logit-regression/Panel_C_MT.dta")
View(Panel_C_MT)
Panel_C_MT_logit <- merge(Panel_C_MT, info_MTOverlap, by = c("UID"), all.x = TRUE)
Panel_C_MT_logit <- merge(Panel_C_MT, info_MTOverlap, by = c("UID"), all.x = TRUE, all.y = FALSE)
Panel_C_T_logit <- merge(Panel_C_T, info_TimberOnly, by = c("UID"), all.x = TRUE)
library(foreign)
write.dta(Panel_C_MT_logit, "Panel_C_MT_logit.dta")
write.dta(Panel_C_T_logit, "Panel_C_T_logit.dta")
rm(Panel_C_MT, Panel_C_T, Panel_C_MT_logit, Panel_C_T_logit)
library(haven)
C_T_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/C_T_panel_mlogit.dta")
View(C_T_panel_mlogit)
library(haven)
C_MT_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/C_MT_panel_mlogit.dta")
View(C_MT_panel_mlogit)
## mlogit model
Panel_C_MT_mlogit <- merge(C_MT_panel_mlogit, info_MTOverlap, by = c("UID"), all.x = TRUE)
Panel_C_T_mlogit <- merge(C_T_panel_mlogit, info_TimberOnly, by = c("UID"), all.x = TRUE)
write.dta(Panel_C_MT_mlogit, "Panel_C_MT_mlogit.dta")
write.dta(Panel_C_T_mlogit, "Panel_C_T_mlogit.dta")
rm(Panel_C_T_mlogit, Panel_C_MT_mlogit, C_MT_panel_mlogit, C_T_panel_mlogit)
View(info_MTOverlap)
View(info_TimberOnly)
library(haven)
C_M_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/C_M_panel_mlogit.dta")
View(C_M_panel_mlogit)
library(haven)
Panel_C_MT_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/Panel_C_MT_mlogit.dta")
View(Panel_C_MT_mlogit)
library(haven)
Panel_C_T_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/Panel_C_T_mlogit.dta")
View(Panel_C_T_mlogit)
library(haven)
T_MT_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/T_MT_panel_mlogit.dta")
View(T_MT_panel_mlogit)
## get issue date information
colnames(Concession_info_TimberOnly)
info_TimberOnly <- Concession_info_TimberOnly %>%
select(UID, YEAR_ISSUE)
library(tidyverse)
library(foreign)
info_TimberOnly <- Concession_info_TimberOnly %>%
select(UID, YEAR_ISSUE)
info_MTOverlap <- Concession_info_MTOverlap %>%
select(UID, YEAR_ISSUE)
info_TandMT <- rbind(info_MTOverlap, info_TimberOnly)
## merge issue year with multinomial logit datasets
C_MT_mlogit <- merge(Panel_C_MT_mlogit, info_MTOverlap, by = c("UID"), all.x = TRUE)
C_T_mlogit <- merge(Panel_C_T_mlogit, info_TimberOnly, by = c("UID"), all.x = TRUE)
T_MT_mlogit <- merge(T_MT_panel_mlogit, info_TandMT, by = c("UID"), all.x = TRUE)
library(haven)
C_MT_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/Old data/C_MT_panel_mlogit.dta")
View(C_MT_panel_mlogit)
library(haven)
C_T_panel_mlogit <- read_dta("~/GitHub/Guyana-concesssion/Stata-mlogit-regression/Old data/C_T_panel_mlogit.dta")
View(C_T_panel_mlogit)
info_TimberOnly <- Concession_info_TimberOnly %>%
select(UID, OWNER, TYPE, ACRES, YEAR_ISSUE)
info_MTOverlap <- Concession_info_MTOverlap %>%
select(UID, OWNER, TYPE, ACRES, YEAR_ISSUE)
info_TandMT <- rbind(info_MTOverlap, info_TimberOnly)
## merge issue year with multinomial logit datasets
C_MT_mlogit <- merge(C_MT_panel_mlogit, info_MTOverlap, by = c("UID"), all.x = TRUE)
C_T_mlogit <- merge(C_T_panel_mlogit, info_TimberOnly, by = c("UID"), all.x = TRUE)
write.dta(C_MT_mlogit, "C_MT_mlogit.dta")
write.dta(C_T_mlogit, "C_T_mlogit.dta")
write.dta(T_MT_mlogit, "T_MT_mlogit.dta")
rm(C_M_panel_mlogit,C_MT_mlogit,C_MT_panel_mlogit,C_T_mlogit,C_T_panel_mlogit,
Panel_C_MT_mlogit,Panel_C_T_mlogit,T_MT_mlogit,T_MT_panel_mlogit)
